#########################################################################################
# TODO: Fill this template out in addition to the code implementation in chatbot.py!    #
#                                                                                       #
# Each "Creative" feature in the rubric has a section below.                            #
# For every feature you chose to implement, replace the "NO" at the end of the relevant #
# lines with "YES".                                                                     #
#                                                                                       #
# You will only receive credit for the features you mark as YES below!                  #
#########################################################################################

FEATURE - Identifying movies without quotation marks and correct capitalization (part 1): YES
FEATURE - Identifying movies without quotation marks and correct capitalization (part 2): YES
FEATURE - Alternate/foreign titles: YES
FEATURE - Disambiguation (part 1): YES
FEATURE - Fine-grained sentiment extraction: YES
FEATURE - Spell-correcting fallback for find_movies_by_title: YES
FEATURE - Extracting sentiment with multiple-movie input: YES
FEATURE - Disambiguation (part 2): YES
FEATURE - Disambiguation (part 3): YES
FEATURE - Dialogue for spell-checking: YES
FEATURE - Dialogue for disambiguation: YES
FEATURE - Communicating sentiments and movies extracted to the user given multiple-movie input: NO
FEATURE - Responding to arbitrary input: YES
FEATURE - Identifying and responding to emotions: YES
Did not implement any of the above features: NO

#########################################################################################
# Team Contributions                                                                    #
#########################################################################################

Michelle worked on Identifying movies without quotation marks and without correct capitalization (part 2), Responding to arbitrary input, and Identifying and responding to emotions.
Leo worked on Disambiguation parts 1, 2, and 3. He also worked on the dialogue from the chatbot and the design of the process function.
Enok worked on the general frameworks of the starter mode code-- mainly recommend and process functions, and "Dialogue for spell-checking" + "Fine-grained sentiment extraction" creative functionalities. Also, the best cheerleader.
Jessica worked on "identifying movies without quotation marks and correct capitalization (part 1)", "alternate/foreign titles", "spell-correcting fallback for find_movies_by_title", "Responding to arbitrary input", and "Identifying and responding to emotions".

#########################################################################################
# Ethics Question                                                                  #
#########################################################################################
TODO: Please answer the following question:

Humans are quick to anthropomorphize chatbots, like ELIZA. 
In the 1960’s, users’ trust in ELIZA raised numerous concerns that humans would believe the system’s advice, 
even if ELIZA did not actually know what it was talking about. Newer chatbots are built using neural networks, 
like those you implemented in PA5. These neural networks are trained on enormous sets of data, from online 
sources like Reddit and Twitter. These sources are interlaced with offensive text that are often reproduced 
in chatbot responses. Furthermore, the newest advanced models, like GPT-3, have produced responses that appear 
that they were written by a human.

What are some possible ramifications of anthropomorphizing chatbot systems? Can you think of any ways that 
engineers could ensure that users can easily distinguish the chatbot responses from those of a human?

If the security around the chatbot system is not strong, anthropomorphizing chatbot systems could potentially result in vulnerable data breaches 
or manipulation on novice or targeted users. To ensure that users can easily distinguish the chatbot responses from those of a human, engineers can provide
visible labels or cues in the chat. For example, writing "(bot)" by the chatbot's name in a bold color whenever it gives a response could make it clearer to the user that
they are interacting with a machine and not a human. 



#########################################################################################
# Optional: Feel free to include anything else that you want us to know about your      #
# implementation!                                                                       #
#########################################################################################
We added and use in chatbot.py (extract_sentiment_creative function) two external txt files that contain extreme positive words and extreme negative words (deps/negative.txt, deps/positive.txt). The two files will be submitted as one deps folder.
